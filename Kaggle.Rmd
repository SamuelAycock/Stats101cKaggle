---
title: "Kaggle Project"
author: "Samuel Aycock and Kendrick Brayman"
date: "November 21, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
#Read the data.
library(glmnet)
library(leaps)
library(caret)
library(MASS)
data  <- read.csv("basketball.csv")
```

```{r}
#Split the data
set.seed(200)
train <- sample(1:dim(data)[1], dim(data)[1]/2)
test <- -train
data_train<- data[train, ]
data_test <- data[test, ]
```


```{r}
#Regsubsets on Hometeam Subset of the Predictors
HTdata <- data[,c(3,115:217)]
dataset_part <- sample(1:3, nrow(HTdata), replace = T, prob = c(0.5, 0.25, 0.25))

p <- ncol(HTdata) - 1
reg1 <- regsubsets(HTWins ~ ., data = HTdata[dataset_part == 1, ], nvmax = p, method = "forward")
reg2 <- regsubsets(HTWins ~ ., data = HTdata[dataset_part == 1, ], nvmax = p, method = "backward")
reg_summary1 <- summary(reg1)
reg_summary2 <- summary(reg2)

coefi <- coef(reg1, id = p)

coefi <- coef(reg2, id = p)
```

```{r}
#Plots for forward selection on full set.
par(mfrow = c(2, 2))

# RSS Plot
plot(reg_summary1$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")

# Adjusted RSq plot
plot(reg_summary1$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "l")
which.max(reg_summary1$adjr2)
points(55, reg_summary1$adjr2[55], col = "red", cex = 2, pch = 20)

# Cp plot (AIC)
plot(reg_summary1$cp, xlab = "Number of Variables", ylab = "AIC", type = "l")
which.min(reg_summary1$cp)
points(40, reg_summary1$cp[40], col = "red", cex = 2, pch = 20)

# BIC plot
plot(reg_summary1$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
which.min(reg_summary1$bic)
points(12, reg_summary1$bic[12], col = "red", cex = 2, pch = 20)
```

```{r}
#Plots for backward selection on full set.
par(mfrow = c(2, 2))

# RSS Plot
plot(reg_summary2$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")

# Adjusted RSq plot
plot(reg_summary2$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "l")
which.max(reg_summary2$adjr2)
points(52, reg_summary2$adjr2[52], col = "red", cex = 2, pch = 20)

# Cp plot
plot(reg_summary2$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
which.min(reg_summary2$cp)
points(42, reg_summary1$cp[42], col = "red", cex = 2, pch = 20)

# BIC plot
plot(reg_summary2$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
which.min(reg_summary2$bic)
points(14, reg_summary2$bic[14], col = "red", cex = 2, pch = 20)
```

```{r}
#Forward Selection Model 1: 30 Predictors
m1 <- glm(HTWins ~  HT.TS.fgm  +  HT.TS.fga  +  HT.TS.tpm  +  HT.TS.tpa  +  HT.TS.fta  +  HT.TS.oreb +  HT.TS.dreb +  HT.TS.ast  + HT.TS.stl    + HT.TS.blk  +  HT.TS.to + HT.TS.pf  + HT.TS.pts +   HT.TA.fgm +   HT.TA.fga +   HT.TA.tpm +   HT.TA.tpa + HT.TA.fta + HT.TA.oreb  + HT.TA.dreb  + HT.TA.ast +   HT.TA.stl + HT.TA.blk   + HT.TA.to+ HT.TA.pf  +   HT.TA.pts + HT.OTS.fgm  + HT.OTS.fga + HT.OTS.tpm +  HT.OTS.tpa  , family = "binomial",data = data_train)
#summary(m1)
#anova(m1)
```

```{r}
#Forward Selection Model 1 (Train)
M1 <- train(HTWins ~  HT.TS.fgm  +  HT.TS.fga  +  HT.TS.tpm  +  HT.TS.tpa  +  HT.TS.fta  +  HT.TS.oreb +  HT.TS.dreb +  HT.TS.ast  + HT.TS.stl    + HT.TS.blk  +  HT.TS.to + HT.TS.pf  + HT.TS.pts +   HT.TA.fgm +   HT.TA.fga +   HT.TA.tpm +   HT.TA.tpa + HT.TA.fta + HT.TA.oreb  + HT.TA.dreb  + HT.TA.ast +   HT.TA.stl + HT.TA.blk   + HT.TA.to+ HT.TA.pf  +   HT.TA.pts + HT.OTS.fgm  + HT.OTS.fga + HT.OTS.tpm +  HT.OTS.tpa, method = "glm",data = data)

#summary(M1)
#confusionMatrix(table(predict(M1)), data_train$HTWins == "Yes")
```

```{r}
#Forward Selection Model 2: Predictor Level Medium (40)
m2 <- glm(HTWins ~ HT.TS.fgm  +  HT.TS.fga  +  HT.TS.tpm  +  HT.TS.tpa  +  HT.TS.fta  +  HT.TS.oreb +  HT.TS.dreb +  HT.TS.ast  + HT.TS.stl    + HT.TS.blk  +  HT.TS.to + HT.TS.pf  + HT.TS.pts +   HT.TA.fgm +   HT.TA.fga +   HT.TA.tpm +   HT.TA.tpa + HT.TA.fta + HT.TA.oreb  + HT.TA.dreb  + HT.TA.ast +   HT.TA.stl + HT.TA.blk   + HT.TA.to+ HT.TA.pf  +   HT.TA.pts + HT.OTS.fgm  + HT.OTS.fga + HT.OTS.tpm +  HT.OTS.tpa +  HT.OTS.fta +  HT.OTS.oreb+ HT.OTS.dreb + HT.OTS.ast  + HT.OTS.stl + HT.OTS.blk +  HT.OTS.to  +  HT.OTS.pf  +  HT.OTS.pts +  HT.OTA.fgm, family = "binomial",data = data_train)
#summary(m2)
#anova(m2)
```

```{r}
#Forward Selection Model 2: Predictor Level Medium (Train)
M2 <- train(HTWins ~ HT.TS.fgm  +  HT.TS.fga  +  HT.TS.tpm  +  HT.TS.tpa  +  HT.TS.fta  +  HT.TS.oreb +  HT.TS.dreb +  HT.TS.ast  + HT.TS.stl    + HT.TS.blk  +  HT.TS.to + HT.TS.pf  + HT.TS.pts +   HT.TA.fgm +   HT.TA.fga +   HT.TA.tpm +   HT.TA.tpa + HT.TA.fta + HT.TA.oreb  + HT.TA.dreb  + HT.TA.ast +   HT.TA.stl + HT.TA.blk   + HT.TA.to+ HT.TA.pf  +   HT.TA.pts + HT.OTS.fgm  + HT.OTS.fga + HT.OTS.tpm +  HT.OTS.tpa +  HT.OTS.fta +  HT.OTS.oreb+ HT.OTS.dreb + HT.OTS.ast  + HT.OTS.stl + HT.OTS.blk +  HT.OTS.to  +  HT.OTS.pf  +  HT.OTS.pts +  HT.OTA.fgm,  method = "glm",data = data)

#summary(M2)
#confusionMatrix(table(predict(M1)), data_train$HTWins == "Yes")
```

```{r}
#Forward Selection Model 2: Predictor Level High (56)
m3 <- glm(HTWins ~ HT.TS.fgm  +  HT.TS.fga  +  HT.TS.tpm  +  HT.TS.tpa  +  HT.TS.fta  +  HT.TS.oreb +  HT.TS.dreb +  HT.TS.ast  + HT.TS.stl    + HT.TS.blk  +  HT.TS.to + HT.TS.pf  + HT.TS.pts +   HT.TA.fgm +   HT.TA.fga +   HT.TA.tpm +   HT.TA.tpa + HT.TA.fta + HT.TA.oreb  + HT.TA.dreb  + HT.TA.ast +   HT.TA.stl + HT.TA.blk   + HT.TA.to+ HT.TA.pf  +   HT.TA.pts + HT.OTS.fgm  + HT.OTS.fga + HT.OTS.tpm +  HT.OTS.tpa +  HT.OTS.fta +  HT.OTS.oreb+ HT.OTS.dreb + HT.OTS.ast  + HT.OTS.stl + HT.OTS.blk +  HT.OTS.to  +  HT.OTS.pf  +  HT.OTS.pts +  HT.OTA.fgm  + HT.OTA.fga + HT.OTA.tpm  + HT.OTA.tpa  + HT.OTA.fta  + HT.OTA.oreb + HT.OTA.dreb + HT.OTA.ast  + HT.OTA.stl  + HT.OTA.blk  + HT.OTA.to + HT.OTA.pf + HT.OTA.pts + HT.S1.plmin +HT.S1.pts  +  HT.S1.min, family = "binomial",data = data_train)
#summary(m3)
#anova(m3)
```

```{r}
#Forward Selection Model 2: Predictor Level High (Train)
M3 <- train(HTWins ~ HT.TS.fgm  +  HT.TS.fga  +  HT.TS.tpm  +  HT.TS.tpa  +  HT.TS.fta  +  HT.TS.oreb +  HT.TS.dreb +  HT.TS.ast  + HT.TS.stl    + HT.TS.blk  +  HT.TS.to + HT.TS.pf  + HT.TS.pts +   HT.TA.fgm +   HT.TA.fga +   HT.TA.tpm +   HT.TA.tpa + HT.TA.fta + HT.TA.oreb  + HT.TA.dreb  + HT.TA.ast +   HT.TA.stl + HT.TA.blk   + HT.TA.to+ HT.TA.pf  +   HT.TA.pts + HT.OTS.fgm  + HT.OTS.fga + HT.OTS.tpm +  HT.OTS.tpa +  HT.OTS.fta +  HT.OTS.oreb+ HT.OTS.dreb + HT.OTS.ast  + HT.OTS.stl + HT.OTS.blk +  HT.OTS.to  +  HT.OTS.pf  +  HT.OTS.pts +  HT.OTA.fgm  + HT.OTA.fga + HT.OTA.tpm  + HT.OTA.tpa  + HT.OTA.fta  + HT.OTA.oreb + HT.OTA.dreb + HT.OTA.ast  + HT.OTA.stl  + HT.OTA.blk  + HT.OTA.to + HT.OTA.pf + HT.OTA.pts + HT.S1.plmin+ HT.S1.pts  +  HT.S1.min, method = "glm",data = data)

#summary(M3)
#confusionMatrix(table(predict(M1)), data_train$HTWins == "Yes")
```

```{r}
#Test the model with the split training data first.
Wins <- factor(c("Yes","No"))
Winpreds <- predict(m1,newdata = data_test,"response")
HTWinspred <- rep(Wins[2], dim(testing)[1])
HTWinspred[Winpreds > .5] <- Wins[1]
confusionmat <- table(HTWinspred, data_test$HTWins)
Accuracy <- (confusionmat[1] + confusionmat[4])/sum(confusionmat)
print(Accuracy)
```

```{r}
#Now test the model on the test data.
testing <- read.csv("basketballtest.csv")

Winpreds <- predict(m1,newdata = testing,"response")
HTWins <- rep(Wins[2], dim(testing)[1])
HTWins[Winpreds > .5] <- Wins[1]

#Save the predictions.
Upload <- data.frame("id" = testing$id,HTWins)
write.csv(Upload,'C:/Users/sama2/OneDrive/Documents/Upload5.csv',row.names = FALSE)
```


































